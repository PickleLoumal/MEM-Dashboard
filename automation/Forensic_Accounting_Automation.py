"""
Forensic Accounting Automation

Generates forensic accounting analysis reports for listed companies using Perplexity AI.
Reads company list from Excel file and fetches stock data from Yahoo Finance.

Environment Variables Required:
- PERPLEXITY_API_KEY: Perplexity AI API key
- PERPLEXITY_API_URL: Perplexity API endpoint (optional, has default)
"""

import os
import datetime
import time
import re
import json
from pathlib import Path

import pandas as pd
import requests
import yfinance as yf
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT

# Load environment variables from .env file if python-dotenv is available
try:
    from dotenv import load_dotenv
    env_path = Path(__file__).resolve().parents[1] / ".env"
    load_dotenv(env_path)
except ImportError:
    pass

# =============================================================================
# Configuration from Environment Variables
# =============================================================================

PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")
PERPLEXITY_API_URL = os.getenv("PERPLEXITY_API_URL", "https://api.perplexity.ai/chat/completions")


def _validate_config():
    """Validate that required environment variables are set."""
    if not PERPLEXITY_API_KEY:
        raise EnvironmentError(
            "Missing required environment variable: PERPLEXITY_API_KEY\n"
            "Please set it in your .env file or system environment."
        )

class YahooFinanceDataFetcher:
    """
    Yahoo Finance æ•°æ®è·å–å™¨ï¼Œä¸“é—¨ç”¨äºè·å–è‚¡ä»·å’Œå¸‚å€¼æ•°æ®
    å®Œå…¨å…è´¹ï¼Œæ— éœ€ API Key
    """

    def __init__(self):
        self.session = None

    def connect(self):
        """
        è¿æ¥åˆ° Yahoo Financeï¼ˆå®é™…ä¸Šä¸éœ€è¦è¿æ¥ï¼Œyfinance æ˜¯å…è´¹çš„ï¼‰
        """
        try:
            print("ğŸ”Œ è¿æ¥åˆ° Yahoo Finance API...")
            self.session = True
            print("âœ… Yahoo Finance å·²å°±ç»ªï¼ˆå…è´¹ï¼Œæ— éœ€ API Keyï¼‰")
            return True
        except Exception as e:
            print(f"âŒ Yahoo Finance åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def get_stock_data(self, symbol):
        """
        è·å–è‚¡ç¥¨çš„å‰ä¸€å¤©æ”¶ç›˜ä»·å’Œå¸‚å€¼æ•°æ®

        å‚æ•°:
        symbol: è‚¡ç¥¨ä»£ç  (å¦‚ '0700.HK', 'AAPL', 'TSLA')

        è¿”å›:
        dict: {'last_price': å‰ä¸€å¤©æ”¶ç›˜ä»·, 'market_cap': å¸‚å€¼, 'currency': è´§å¸}
        """
        try:
            if not self.session:
                print("è¯·å…ˆè¿æ¥ Yahoo Finance")
                return None

            print(f"ğŸ“Š ä» Yahoo Finance è·å– {symbol} çš„æ•°æ®...")

            # ä½¿ç”¨ yfinance è·å–è‚¡ç¥¨æ•°æ®
            ticker = yf.Ticker(symbol)

            # è·å–è‚¡ç¥¨ä¿¡æ¯
            info = ticker.info

            # è·å–å†å²æ•°æ®ï¼ˆæœ€è¿‘2å¤©ï¼Œç¡®ä¿èƒ½æ‹¿åˆ°å‰æ”¶ç›˜ä»·ï¼‰
            hist = ticker.history(period='2d')

            # æå–æ•°æ®
            price_value = None
            market_cap_value = None
            currency_value = None

            # è·å–å‰æ”¶ç›˜ä»·
            if not hist.empty and len(hist) > 0:
                # è·å–æœ€åä¸€ä¸ªäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»·ï¼ˆå‰æ”¶ç›˜ä»·ï¼‰
                price_value = hist['Close'].iloc[-1]
                print(f"âœ… å‰æ”¶ç›˜ä»·: {price_value}")

            # è·å–å¸‚å€¼
            if 'marketCap' in info:
                market_cap_value = info['marketCap']
                print(f"âœ… å¸‚å€¼: {market_cap_value}")

            # è·å–è´§å¸
            if 'currency' in info:
                currency_value = info['currency']
                print(f"âœ… è´§å¸: {currency_value}")
            elif 'financialCurrency' in info:
                currency_value = info['financialCurrency']
                print(f"âœ… è´§å¸: {currency_value}")

            result = {
                'symbol': symbol,
                'last_price': price_value,
                'market_cap': market_cap_value,
                'currency': currency_value
            }

            print(f"âœ… æ•°æ®è·å–æˆåŠŸ: å‰æ”¶ç›˜ä»·={result['last_price']}, å¸‚å€¼={result['market_cap']}, è´§å¸={result['currency']}")
            return result
        except Exception as e:
            print(f"âŒ è·å– {symbol} æ•°æ®æ—¶å‡ºé”™: {e}")
            print(f"ğŸ’¡ æç¤º: è¯·ç¡®è®¤è‚¡ç¥¨ä»£ç æ ¼å¼æ­£ç¡®ï¼ˆå¦‚ 0700.HK, AAPL, TSLAï¼‰")
            return None

    def disconnect(self):
        """
        æ–­å¼€è¿æ¥ï¼ˆYahoo Finance ä¸éœ€è¦æ–­å¼€ï¼‰
        """
        try:
            if self.session:
                self.session = None
                print("âœ… Yahoo Finance ä¼šè¯å·²ç»“æŸ")
        except Exception as e:
            print(f"âŒ æ–­å¼€è¿æ¥å¤±è´¥: {e}")

def convert_markdown_to_word(markdown_text, doc):
    """
    å°†Markdownæ–‡æœ¬è½¬æ¢ä¸ºWordæ–‡æ¡£æ ¼å¼ï¼Œä¸¥æ ¼æŒ‰ç…§markdownè¯­æ³•æ ‡å‡†
    æ”¯æŒçº¢ç»¿ç¯emojiè¡¨æƒ…: ğŸŸ¢, ğŸŸ¡, ğŸ”´
    """
    lines = markdown_text.split('\n')
    in_code_block = False
    code_language = ""
    in_table = False
    table_obj = None

    for line in lines:
        # å¤„ç†ä»£ç å—
        if line.strip().startswith('```'):
            if not in_code_block:
                # å¼€å§‹ä»£ç å—
                in_code_block = True
                code_language = line.strip()[3:].strip()  # è·å–è¯­è¨€æ ‡è¯†
                continue
            else:
                # ç»“æŸä»£ç å—
                in_code_block = False
                code_language = ""
                continue

        if in_code_block:
            # ä»£ç å—å†…å®¹ç”¨ç­‰å®½å­—ä½“ï¼Œä¿æŒåŸå§‹æ ¼å¼
            p = doc.add_paragraph(line)
            for run in p.runs:
                run.font.name = 'Courier New'
                run.font.size = Pt(10)
            continue

        # æ£€æµ‹è¡¨æ ¼ï¼ˆç®€å•çš„markdownè¡¨æ ¼æ£€æµ‹ï¼‰
        if '|' in line and line.strip().startswith('|'):
            if not in_table:
                # å¼€å§‹æ–°è¡¨æ ¼
                in_table = True
                # è§£æè¡¨å¤´
                cells = [cell.strip() for cell in line.strip().split('|')[1:-1]]
                table_obj = doc.add_table(rows=1, cols=len(cells))
                table_obj.style = 'Table Grid'
                for i, cell_text in enumerate(cells):
                    table_obj.rows[0].cells[i].text = cell_text
            elif line.strip().replace('|', '').replace('-', '').replace(' ', '').replace(':', '') == '':
                # è¡¨æ ¼åˆ†éš”çº¿ï¼Œè·³è¿‡
                continue
            else:
                # æ·»åŠ è¡¨æ ¼è¡Œ
                cells = [cell.strip() for cell in line.strip().split('|')[1:-1]]
                row_cells = table_obj.add_row().cells
                for i, cell_text in enumerate(cells):
                    if i < len(row_cells):
                        row_cells[i].text = cell_text
            continue
        else:
            if in_table:
                in_table = False
                table_obj = None

        # è·³è¿‡ç©ºè¡Œä½†ä¿ç•™æ®µè½é—´è·
        if not line.strip():
            doc.add_paragraph()
            continue

        # å¤„ç†å„çº§æ ‡é¢˜ - å¿…é¡»æ˜¯è¡Œé¦–ä¸”åé¢æœ‰ç©ºæ ¼
        if line.startswith('# ') and not line.startswith('## '):
            heading = doc.add_heading(line[2:].strip(), level=1)
        elif line.startswith('## ') and not line.startswith('### '):
            heading = doc.add_heading(line[3:].strip(), level=2)
        elif line.startswith('### ') and not line.startswith('#### '):
            heading = doc.add_heading(line[4:].strip(), level=3)
        elif line.startswith('#### ') and not line.startswith('##### '):
            heading = doc.add_heading(line[5:].strip(), level=4)
        elif line.startswith('##### ') and not line.startswith('###### '):
            heading = doc.add_heading(line[6:].strip(), level=5)

        # å¤„ç†æ— åºåˆ—è¡¨ - æ”¯æŒç¼©è¿›
        elif re.match(r'^[ \t]*[-*+] ', line):
            # è®¡ç®—ç¼©è¿›çº§åˆ«
            indent_match = re.match(r'^([ \t]*)', line)
            indent_level = len(indent_match.group(1).expandtabs(4)) // 4 if indent_match else 0

            # æå–åˆ—è¡¨å†…å®¹
            bullet_text = re.sub(r'^[ \t]*[-*+] ', '', line)

            # åˆ›å»ºåˆ—è¡¨é¡¹
            p = doc.add_paragraph(style='List Bullet')
            add_formatted_text(p, bullet_text)

        # å¤„ç†æœ‰åºåˆ—è¡¨
        elif re.match(r'^[ \t]*\d+\. ', line):
            # æå–åˆ—è¡¨å†…å®¹
            bullet_text = re.sub(r'^[ \t]*\d+\. ', '', line)
            p = doc.add_paragraph(style='List Number')
            add_formatted_text(p, bullet_text)

        # å¤„ç†æ°´å¹³åˆ†å‰²çº¿
        elif line.strip() in ['---', '***', '___'] or re.match(r'^[ \t]*[-*_]{3,}[ \t]*$', line):
            # æ·»åŠ æ°´å¹³çº¿
            p = doc.add_paragraph()
            p.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
            run = p.add_run('â”€' * 50)
            run.font.color.rgb = RGBColor(128, 128, 128)

        # å¤„ç†å¼•ç”¨å— (ä»¥ > å¼€å¤´)
        elif line.strip().startswith('> '):
            quote_text = line.strip()[2:]
            p = doc.add_paragraph()
            p.left_indent = Inches(0.5)
            p.paragraph_format.left_indent = Inches(0.5)
            add_formatted_text(p, quote_text)

        # å¤„ç†æ™®é€šæ®µè½
        else:
            if line.strip():
                p = doc.add_paragraph()
                add_formatted_text(p, line.strip())

    return doc

def add_formatted_text(paragraph, text):
    """
    å‘æ®µè½æ·»åŠ æ ¼å¼åŒ–æ–‡æœ¬ï¼ŒæŒ‰ç…§æ­£ç¡®çš„markdownä¼˜å…ˆçº§å¤„ç†
    æ”¯æŒemojiï¼ˆåŒ…æ‹¬çº¢ç»¿ç¯: ğŸŸ¢, ğŸŸ¡, ğŸ”´ï¼‰
    """
    # æŒ‰ç…§markdownæ ‡å‡†çš„ä¼˜å…ˆçº§å¤„ç†ï¼šå…ˆå¤„ç†åŠ ç²—ï¼Œå†å¤„ç†æ–œä½“ï¼Œæœ€åå¤„ç†è¡Œå†…ä»£ç 

    # 1. å…ˆå¤„ç†è¡Œå†…ä»£ç  `code` (æœ€é«˜ä¼˜å…ˆçº§ï¼Œä¸èƒ½è¢«å…¶ä»–æ ¼å¼å½±å“)
    code_parts = re.split(r'(`[^`]*`)', text)

    for code_part in code_parts:
        if code_part.startswith('`') and code_part.endswith('`') and len(code_part) >= 2:
            # è¡Œå†…ä»£ç  - ç›´æ¥æ·»åŠ ï¼Œä¸å¤„ç†å…¶ä»–æ ¼å¼
            run = paragraph.add_run(code_part[1:-1])
            run.font.name = 'Courier New'
        else:
            # 2. å¤„ç†åŠ ç²—æ–‡æœ¬ **text** (é«˜ä¼˜å…ˆçº§)
            bold_parts = re.split(r'(\*\*[^*]*\*\*)', code_part)

            for bold_part in bold_parts:
                if bold_part.startswith('**') and bold_part.endswith('**') and len(bold_part) >= 4:
                    # åŠ ç²—æ–‡æœ¬ - å†…å®¹è¿˜å¯èƒ½åŒ…å«æ–œä½“
                    bold_content = bold_part[2:-2]
                    # åœ¨åŠ ç²—æ–‡æœ¬å†…éƒ¨å¤„ç†æ–œä½“
                    italic_parts = re.split(r'(\*[^*]+\*)', bold_content)

                    for italic_part in italic_parts:
                        if italic_part.startswith('*') and italic_part.endswith('*') and len(italic_part) >= 3:
                            # åŠ ç²—+æ–œä½“
                            run = paragraph.add_run(italic_part[1:-1])
                            run.bold = True
                            run.italic = True
                        else:
                            # åªåŠ ç²—
                            if italic_part:
                                run = paragraph.add_run(italic_part)
                                run.bold = True
                else:
                    # 3. å¤„ç†æ–œä½“æ–‡æœ¬ *text* (ä½ä¼˜å…ˆçº§)
                    italic_parts = re.split(r'(\*[^*]+\*)', bold_part)

                    for italic_part in italic_parts:
                        if italic_part.startswith('*') and italic_part.endswith('*') and len(italic_part) >= 3:
                            # æ–œä½“æ–‡æœ¬
                            run = paragraph.add_run(italic_part[1:-1])
                            run.italic = True
                        else:
                            # æ™®é€šæ–‡æœ¬ï¼ˆåŒ…å«emojiï¼‰
                            if italic_part:
                                paragraph.add_run(italic_part)

# Forensic Accounting Prompt Template
forensic_template = """{} ({})
Forensic and accounts investigation, As of today's date [{}]
Stock Price (Previous Close): {} {}
Market Cap: {} {}

Can you perform forensic accounting on the said company using their quarterly and annual reports?
Where it is possible to do so, please state definitively (a) whether accounting tricks most probably have been applied, (b) the probable accounting consequence (e.g. inflating sales, capitalizing cost so they don't deducted from income statements, (c ) hiding or deferring financial and repayment liabilities.
Please consider the extent of the most probable tricks and intent and conclude this analysis of whether there is high probability of extensive accounting problems.
For each section and sub-section, can you please state the section heading, and if nothing bad is found you will just say so. This allows users better understanding that you have covered everything.

Type - Revenue Recognition Tricks
These involve prematurely or fictitiously booking sales to inflate top-line growth.
Trick - Explanation
Channel Stuffing:
Flooding distributors with excess inventory at period-end to recognize revenue early, even without real demand. Example: Bristol-Myers Squibb inflated earnings by $1.5 billion through wholesaler overloads.
Bill-and-Hold Sales:
Booking revenue for goods "sold" but still held by the company for the buyer, often with side agreements allowing returns. Example: Alere Inc. recognized $24 million prematurely via third-party storage deals.
Round-Tripping
Circular transactions where funds are swapped between related parties (e.g., via loans disguised as sales) to create fake revenue. Example: Used in the Enron scandal to fabricate energy trading volumes.
Fake Sales (Fictitious Revenue)
Inventing sales from bogus invoices or ghost customers. Example: Luckin Coffee fabricated $300 million in 2019 revenue, leading to delisting.
Improper Timing of Revenue Recognition
Accelerating future sales into the current period or delaying them post-targets. Example: Marvell Technology pulled in 5-16% of quarterly revenue from future periods.
Third-Party Transactions
Deceptive deals like consignment sales masked as outright purchases. Often overlaps with bill-and-hold.

Type - Expense Manipulation
These defer or hide costs to overstate current profits.
Capitalizing Expenses (Improper Capitalization)
Treating operating costs (e.g., R&D or maintenance) as long-term assets to amortize over time instead of expensing immediately. Example: WorldCom capitalized $9 billion in line costs, inflating assets.
Cookie Jar Reserves
Over-provisioning for future expenses (e.g., excessive bad debt allowances) then reversing them in good periods to boost earnings. Example: Sunbeam used reserves to smooth income across quarters.
Deferred Expenses
Delaying recognition of costs through arbitrary accruals or inventory over-allocation. Often part of broader expense schemes.
Other Improper Expense Recognition
Understating liabilities like warranties or skipping impairments. Example: Celadon Group hid $20 million in asset write-downs via fake sales.

Type - Earnings Management
These smooth or manipulate overall profitability to meet targets or mislead analysts.
Trick - Explanation
Big Bath Accounting
Taking large one-time write-offs during bad periods to "clean the slate," making future earnings look stronger. Example: Used by banks post-2008 crisis to dump losses.
Earnings Smoothing
Averaging income over periods via reserves or estimates to avoid volatility. Example: General Electric smoothed earnings through insurance reserve manipulations.
Misclassifying Non-Recurrent Items
Labeling ongoing costs as "one-time" to exclude them from core earnings. Often tied to non-GAAP tweaks.
Fraudulent Management Estimates
Biasing subjective judgments (e.g., depreciation rates) to shift income. Example: Computer Sciences Corp. used flawed models, settling for $190 million.
Misleading Non-GAAP Reporting
Adjusting metrics like "pro forma" earnings to exclude real expenses. Example: Brixmor Property Group inflated same-store metrics, fined $7 million.

Type - Balance Sheet Shenanigans
These distort asset/liability portrayals to hide debt or overstate value.
Trick - Explanation
Off-Balance Sheet Financing
Hiding debt through special purpose entities (SPEs) or leases not consolidated. Example: Enron's SPEs concealed $13 billion in liabilities.
Improper Asset Valuation
Overvaluing inventory, intangibles, or investments via aggressive assumptions. Example: Valeant Pharmaceuticals inflated drug asset values pre-crash.
Understated Liabilities
Failing to accrue contingencies like lawsuits or pensions. Example: Toshiba understated $1.2 billion in cost overruns in 2015.

Type - Cash Flow Manipulation
These make operating cash look healthier than it is.
Trick - Explanation
Misclassifying Cash Flows
Shifting operating outflows to investing/financing (e.g., calling vendor prepayments "investments"). Example: Used by tech firms to boost free cash flow metrics.
Timing Tricks
Delaying supplier payments or accelerating collections to window-dress period-end cash. Often overlaps with revenue timing.

Type - Tax and Regulatory Evasion
These exploit loopholes to reduce reported taxes or skirt rules.
Trick - Explanation
Transfer Pricing Abuse
Shifting profits to low-tax jurisdictions via inflated inter-company sales. Example: Apple faced EU fines of â‚¬13 billion for Irish transfer pricing.
Tax Deferral Games
Aggressive use of NOL carryforwards or hybrid instruments to defer taxes indefinitely. Example: General Electric deferred billions through offshore structures.
Misleading Forecasts or Projections
Issuing false guidance to avoid regulatory scrutiny on shortfalls. Example: Walgreens reaffirmed optimistic merger projections, settling for $34.5 million.
Excessive use of supplier financing
Normal supplier financing is expressed in average days to payment. It can be between 30 days to 45 days. Some companies stretch that out to over 100 days or even 150 days, and they can bully suppliers because of their purchase size. This saves on the company having to borrow more to sustain its business. But in fact the financial conditions at this company is tighter and actual operational profits are much lower than stated in the accounts.

Cross-Cutting: Inadequate Internal Controls (ICFR)
This isn't a specific trick but enables many others by failing to detect/prevent them. Example: Monsanto's weak rebate controls led to an $80 million penalty.

This integrated list covers the most prevalent tactics from forensic accounting literature (e.g., SEC enforcement actions). It's more granular than my original but avoids redundancy.
Please add Traffic-light flag: ğŸŸ¢, ğŸŸ¡ , ğŸ”´ to those sections where significant bad situations are found.
At the end of your report will you please compile a table showing the serious forensic problems found and a summary statement of effects on sales or profitability or on financial stability.
"""

########################## ä¸»ç¨‹åº ##########################

# Perplexity API å‡½æ•°
def call_perplexity_api(prompt, max_retries=3):
    """è°ƒç”¨ Perplexity Sonar Deep Research API"""
    headers = {
        "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
        "Content-Type": "application/json"
    }

    data = {
        "model": "sonar-deep-research",
        "messages": [
            {
                "role": "system",
                "content": "You are a highly intelligent forensic accounting expert and AI assistant with deep research capabilities."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]
    }

    for attempt in range(max_retries):
        try:
            response = requests.post(
                PERPLEXITY_API_URL,
                headers=headers,
                json=data,
                timeout=3600  # 1å°æ—¶è¶…æ—¶ï¼Œé€‚åº”æ·±åº¦ç ”ç©¶æ¨¡å¼
            )
            response.raise_for_status()
            result = response.json()

            if result and "choices" in result and len(result["choices"]) > 0:
                content = result["choices"][0]["message"]["content"]
                # ç§»é™¤ <think> æ ‡ç­¾å†…å®¹ï¼ˆæ¨ç†è¿‡ç¨‹ï¼‰
                content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL)
                return content.strip()
            else:
                raise Exception("APIè¿”å›æ ¼å¼å¼‚å¸¸")

        except Exception as e:
            print(f"âš ï¸  APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
            if attempt < max_retries - 1:
                time.sleep(5)
            else:
                raise

    return None


# =============================================================================
# Main Execution
# =============================================================================

# Validate configuration before starting
_validate_config()

# è¯»å–Excelæ–‡ä»¶è·å–å…¬å¸åˆ—è¡¨å’Œè‚¡ç¥¨ä»£ç 
today = datetime.datetime.now().strftime("%Y-%m-%d")
today_short = datetime.datetime.now().strftime("%m%d")  # è·å–æœˆæ—¥æ ¼å¼ï¼Œå¦‚0905
excel_filename = f"List - {today_short}.xlsx"  # åŒ¹é…å®é™…æ–‡ä»¶åæ ¼å¼
# ä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•ä½œä¸ºåŸºç¡€è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
excel_path = os.path.join(script_dir, excel_filename)

print(f"ğŸ“Š æ­£åœ¨è¯»å–Excelæ–‡ä»¶: {excel_path}")

try:
    # è¯»å–Excelæ–‡ä»¶
    df = pd.read_excel(excel_path, skiprows=0)

    # ä»Aåˆ—è¯»å–å…¬å¸åç§°ï¼Œä»Båˆ—è¯»å–è‚¡ç¥¨ä»£ç ï¼Œä»Fåˆ—è¯»å–æ–‡ä»¶å
    companies = df.iloc[:, 0].dropna().tolist()  # Aåˆ—ï¼ˆç¬¬0åˆ—ï¼‰
    tickers = df.iloc[:, 1].dropna().tolist()    # Båˆ—ï¼ˆç¬¬1åˆ—ï¼‰
    file_names = df.iloc[:, 5].dropna().tolist() # Fåˆ—ï¼ˆç¬¬5åˆ—ï¼‰

    # ç¡®ä¿ä¸‰ä¸ªåˆ—è¡¨é•¿åº¦ä¸€è‡´
    min_length = min(len(companies), len(tickers), len(file_names))
    companies = companies[:min_length]
    tickers = tickers[:min_length]
    file_names = file_names[:min_length]

    print(f"âœ… æˆåŠŸè¯»å– {len(companies)} å®¶å…¬å¸:")
    for i, (company, ticker, filename) in enumerate(zip(companies, tickers, file_names), 1):
        print(f"   {i}. {company} ({ticker}) - æ–‡ä»¶å: {filename}")

except FileNotFoundError:
    print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {excel_path}")
    print(f"ğŸ“ è¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨ä¸”å‘½åæ ¼å¼ä¸º 'List-{today_short}.xlsx'")
    exit(1)
except Exception as e:
    print(f"âŒ è¯»å–Excelæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    exit(1)

start_time = datetime.datetime.now()

# Create output directory with today's dateï¼ˆåŸºäºè„šæœ¬æ‰€åœ¨ç›®å½•ï¼‰
output_base_dir = os.path.join(script_dir, "output")
output_dir = os.path.join(output_base_dir, today)
if not os.path.exists(output_dir):
    os.makedirs(output_dir, exist_ok=True)
    print(f"âœ… Created output directory: {output_dir}")

# åˆå§‹åŒ–è¿è¡Œæ—¥å¿—
run_log = []
successful_reports = []
failed_reports = []

print(f"\nğŸš€ å¼€å§‹å¤„ç† {len(companies)} å®¶å…¬å¸çš„å–è¯ä¼šè®¡åˆ†ææŠ¥å‘Š...")
print(f"ğŸ“… æ—¥æœŸ: {today}")
print("=" * 60)

run_log.append(f"ğŸš€ å¼€å§‹å¤„ç† {len(companies)} å®¶å…¬å¸çš„å–è¯ä¼šè®¡åˆ†ææŠ¥å‘Š...")
run_log.append(f"ğŸ“… æ—¥æœŸ: {today}")
run_log.append("=" * 60)

# åˆå§‹åŒ– Yahoo Finance æ•°æ®è·å–å™¨
yahoo_fetcher = YahooFinanceDataFetcher()
yahoo_connected = yahoo_fetcher.connect()

if not yahoo_connected:
    print("âš ï¸ Yahoo Finance è¿æ¥å¤±è´¥ï¼Œå°†ä½¿ç”¨ç©ºå€¼ä½œä¸ºè‚¡ä»·å’Œå¸‚å€¼æ•°æ®")

for i, (company, ticker, file_name) in enumerate(zip(companies, tickers, file_names), 1):
    company_start_time = datetime.datetime.now()
    print(f"\nğŸ“Š æ­£åœ¨å¤„ç†ç¬¬ {i}/{len(companies)} å®¶å…¬å¸: {company} ({ticker}) - æ–‡ä»¶å: {file_name}")
    print(f"â° å¼€å§‹æ—¶é—´: {company_start_time.strftime('%H:%M:%S')}")

    run_log.append(f"\nğŸ“Š æ­£åœ¨å¤„ç†ç¬¬ {i}/{len(companies)} å®¶å…¬å¸: {company} ({ticker}) - æ–‡ä»¶å: {file_name}")
    run_log.append(f"â° å¼€å§‹æ—¶é—´: {company_start_time.strftime('%H:%M:%S')}")

    # è·å–è‚¡ä»·å’Œå¸‚å€¼æ•°æ®
    stock_data = None
    stock_price_text = "N/A"
    market_cap_text = "N/A"
    currency = ""

    if yahoo_connected:
        try:
            print(f"ğŸ’° ä» Yahoo Finance è·å– {ticker} çš„æ•°æ®...")
            stock_data = yahoo_fetcher.get_stock_data(ticker)

            if stock_data and stock_data['last_price'] is not None:
                stock_price_text = f"{stock_data['last_price']:.2f}"
                currency = stock_data.get('currency', '')

                if stock_data['market_cap'] is not None:
                    # æ ¼å¼åŒ–å¸‚å€¼
                    market_cap_value = stock_data['market_cap']
                    if market_cap_value >= 1e12:
                        market_cap_text = f"{market_cap_value/1e12:.2f}T"
                    elif market_cap_value >= 1e9:
                        market_cap_text = f"{market_cap_value/1e9:.2f}B"
                    elif market_cap_value >= 1e6:
                        market_cap_text = f"{market_cap_value/1e6:.2f}M"
                    else:
                        market_cap_text = f"{market_cap_value:,.0f}"

                print(f"âœ… è·å–æˆåŠŸ: å‰æ”¶ç›˜ä»·={stock_price_text} {currency}, å¸‚å€¼={market_cap_text} {currency}")
                run_log.append(f"âœ… è‚¡ä»·æ•°æ®: å‰æ”¶ç›˜ä»·={stock_price_text} {currency}, å¸‚å€¼={market_cap_text} {currency}")
            else:
                print(f"âš ï¸ æœªèƒ½è·å– {ticker} çš„æœ‰æ•ˆæ•°æ®")
                run_log.append(f"âš ï¸ æœªèƒ½è·å– {ticker} çš„æœ‰æ•ˆæ•°æ®")

        except Exception as e:
            print(f"âŒ è·å–è‚¡ä»·æ•°æ®æ—¶å‡ºé”™: {e}")
            run_log.append(f"âŒ è·å–è‚¡ä»·æ•°æ®æ—¶å‡ºé”™: {e}")

    # Generate the prompt with stock price and market cap data
    prompt = forensic_template.format(company, ticker, today, stock_price_text, currency, market_cap_text, currency)

    # é‡è¯•æœºåˆ¶
    max_retries = 3
    retry_count = 0
    success = False

    while retry_count < max_retries and not success:
        try:
            print(f"ğŸ”„ å°è¯•ç¬¬ {retry_count + 1}/{max_retries} æ¬¡è°ƒç”¨AI API...")
            run_log.append(f"ğŸ”„ å°è¯•ç¬¬ {retry_count + 1}/{max_retries} æ¬¡è°ƒç”¨AI API...")

            # è°ƒç”¨ Perplexity API
            print("â³ ç­‰å¾…Perplexity AIç”Ÿæˆå–è¯ä¼šè®¡åˆ†ææŠ¥å‘Š...")
            run_log.append("â³ ç­‰å¾…Perplexity AIç”Ÿæˆå–è¯ä¼šè®¡åˆ†ææŠ¥å‘Š...")

            response_content = call_perplexity_api(prompt, max_retries=1)

            # éªŒè¯å“åº”å†…å®¹
            if response_content and len(response_content.strip()) > 100:
                # è½¬æ¢Markdownä¸ºWordæ ¼å¼
                print("ğŸ“ è½¬æ¢Markdownæ ¼å¼åˆ°Word...")
                run_log.append("ğŸ“ è½¬æ¢Markdownæ ¼å¼åˆ°Word...")

                # Create a new Word document
                doc = Document()
                doc = convert_markdown_to_word(response_content, doc)

                # Save file to the dated output directory with "FA -" prefix
                output_filename = os.path.join(output_dir, f"FA - {file_name}.docx")
                doc.save(output_filename)

                company_end_time = datetime.datetime.now()
                processing_time = (company_end_time - company_start_time).total_seconds()

                print(f"âœ… æˆåŠŸä¿å­˜: {output_filename}")
                print(f"ğŸ“„ å†…å®¹é•¿åº¦: {len(response_content)} å­—ç¬¦")
                print(f"ğŸ“ å·²è½¬æ¢ä¸ºæ ¼å¼åŒ–Wordæ–‡æ¡£")
                print(f"â±ï¸  å¤„ç†è€—æ—¶: {processing_time:.1f} ç§’")

                run_log.append(f"âœ… æˆåŠŸä¿å­˜: {output_filename}")
                run_log.append(f"ğŸ“„ å†…å®¹é•¿åº¦: {len(response_content)} å­—ç¬¦")
                run_log.append(f"ğŸ“ å·²è½¬æ¢ä¸ºæ ¼å¼åŒ–Wordæ–‡æ¡£")
                run_log.append(f"â±ï¸  å¤„ç†è€—æ—¶: {processing_time:.1f} ç§’")

                successful_reports.append({
                    'company': company,
                    'ticker': ticker,
                    'filename': output_filename,
                    'content_length': len(response_content),
                    'processing_time': processing_time,
                    'completed_at': company_end_time.strftime('%H:%M:%S')
                })

                success = True

            else:
                print(f"âš ï¸  AIè¿”å›å†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œå‡†å¤‡é‡è¯•...")
                run_log.append(f"âš ï¸  AIè¿”å›å†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œå‡†å¤‡é‡è¯•...")
                retry_count += 1
                if retry_count < max_retries:
                    wait_time = 10 * retry_count
                    print(f"â¸ï¸  ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    run_log.append(f"â¸ï¸  ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)

        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            run_log.append(f"âŒ é”™è¯¯: {e}")
            retry_count += 1
            if retry_count < max_retries:
                wait_time = 15 * retry_count
                print(f"â¸ï¸  ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                run_log.append(f"â¸ï¸  ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)

    if not success:
        print(f"ğŸš« {company} å¤„ç†å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
        run_log.append(f"ğŸš« {company} å¤„ç†å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")

        # åˆ›å»ºä¸€ä¸ªé”™è¯¯æ–‡ä»¶è®°å½•
        error_filename = os.path.join(output_dir, f"ERROR - FA - {file_name}.txt")
        with open(error_filename, 'w', encoding='utf-8') as f:
            f.write(f"å¤„ç†å¤±è´¥\nå…¬å¸: {company}\nè‚¡ç¥¨ä»£ç : {ticker}\næ–‡ä»¶å: {file_name}\næ—¶é—´: {datetime.datetime.now()}\n")
        print(f"ğŸ“ é”™è¯¯è®°å½•å·²ä¿å­˜: {error_filename}")
        run_log.append(f"ğŸ“ é”™è¯¯è®°å½•å·²ä¿å­˜: {error_filename}")

        failed_reports.append({
            'company': company,
            'ticker': ticker,
            'error_file': error_filename,
            'failed_at': datetime.datetime.now().strftime('%H:%M:%S')
        })

    # å…¬å¸é—´ç­‰å¾…æ—¶é—´
    if i < len(companies):
        print(f"â¸ï¸  ç­‰å¾… 5 ç§’åå¤„ç†ä¸‹ä¸€å®¶å…¬å¸...")
        run_log.append(f"â¸ï¸  ç­‰å¾… 5 ç§’åå¤„ç†ä¸‹ä¸€å®¶å…¬å¸...")
        time.sleep(5)

# è®¡ç®—æ€»è€—æ—¶
end_time = datetime.datetime.now()
total_time = (end_time - start_time).total_seconds()

print(f"\nğŸ‰ æ‰€æœ‰å…¬å¸å¤„ç†å®Œæˆ!")
print(f"ğŸ“ æ–‡ä»¶ä¿å­˜ä½ç½®: {output_dir}")
print(f"â° å®Œæˆæ—¶é—´: {end_time.strftime('%H:%M:%S')}")
print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f} ç§’ ({total_time/60:.1f} åˆ†é’Ÿ)")

run_log.append(f"\nğŸ‰ æ‰€æœ‰å…¬å¸å¤„ç†å®Œæˆ!")
run_log.append(f"ğŸ“ æ–‡ä»¶ä¿å­˜ä½ç½®: {output_dir}")
run_log.append(f"â° å®Œæˆæ—¶é—´: {end_time.strftime('%H:%M:%S')}")
run_log.append(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f} ç§’ ({total_time/60:.1f} åˆ†é’Ÿ)")

# ç”Ÿæˆè¿è¡ŒæŠ¥å‘ŠWordæ–‡æ¡£
report_doc = Document()

# æ·»åŠ æ ‡é¢˜
title = report_doc.add_heading('Forensic Accounting Analysis - Execution Report', 0)
title.alignment = 1  # å±…ä¸­

# æ·»åŠ æ€»ç»“æ®µè½
summary = report_doc.add_heading('ğŸ“Š Execution Summary', level=1)

# åˆ›å»ºæ€»ç»“è¡¨æ ¼
summary_table = report_doc.add_table(rows=1, cols=2)
summary_table.style = 'Table Grid'

# è¡¨æ ¼æ ‡é¢˜è¡Œ
hdr_cells = summary_table.rows[0].cells
hdr_cells[0].text = 'Item'
hdr_cells[1].text = 'Result'

# æ·»åŠ æ€»ç»“æ•°æ®
summary_data = [
    ('Execution Date', today),
    ('Start Time', start_time.strftime('%H:%M:%S')),
    ('End Time', end_time.strftime('%H:%M:%S')),
    ('Total Duration', f"{total_time:.1f} seconds ({total_time/60:.1f} minutes)"),
    ('Total Companies to Process', str(len(companies))),
    ('Successful Reports Generated', str(len(successful_reports))),
    ('Failed Reports', str(len(failed_reports))),
    ('Success Rate', f"{len(successful_reports)/len(companies)*100:.1f}%")
]

for item, value in summary_data:
    row_cells = summary_table.add_row().cells
    row_cells[0].text = item
    row_cells[1].text = value

# æ·»åŠ æˆåŠŸæŠ¥å‘Šè¯¦æƒ…
if successful_reports:
    success_heading = report_doc.add_heading('âœ… Successfully Generated Reports', level=1)

    success_table = report_doc.add_table(rows=1, cols=5)
    success_table.style = 'Table Grid'

    hdr_cells = success_table.rows[0].cells
    hdr_cells[0].text = 'Company Name'
    hdr_cells[1].text = 'Stock Code'
    hdr_cells[2].text = 'Completion Time'
    hdr_cells[3].text = 'Processing Time (sec)'
    hdr_cells[4].text = 'Content Length (chars)'

    for report in successful_reports:
        row_cells = success_table.add_row().cells
        row_cells[0].text = report['company']
        row_cells[1].text = report['ticker']
        row_cells[2].text = report['completed_at']
        row_cells[3].text = f"{report['processing_time']:.1f}"
        row_cells[4].text = str(report['content_length'])

# æ·»åŠ å¤±è´¥æŠ¥å‘Šè¯¦æƒ…
if failed_reports:
    failed_heading = report_doc.add_heading('âŒ Failed Reports', level=1)

    failed_table = report_doc.add_table(rows=1, cols=3)
    failed_table.style = 'Table Grid'

    hdr_cells = failed_table.rows[0].cells
    hdr_cells[0].text = 'Company Name'
    hdr_cells[1].text = 'Stock Code'
    hdr_cells[2].text = 'Failed Time'

    for report in failed_reports:
        row_cells = failed_table.add_row().cells
        row_cells[0].text = report['company']
        row_cells[1].text = report['ticker']
        row_cells[2].text = report['failed_at']

# æ·»åŠ è¯¦ç»†è¿è¡Œæ—¥å¿—
log_heading = report_doc.add_heading('ğŸ“‹ Detailed Execution Log', level=1)

for log_entry in run_log:
    report_doc.add_paragraph(log_entry)

# ä¿å­˜è¿è¡ŒæŠ¥å‘Š
report_filename = os.path.join(output_dir, f"FA Execution Report - {today} - {end_time.strftime('%H%M%S')}.docx")
report_doc.save(report_filename)

# æ–­å¼€ Yahoo Finance è¿æ¥
if yahoo_connected:
    yahoo_fetcher.disconnect()

print(f"ğŸ“„ è¿è¡ŒæŠ¥å‘Šå·²ä¿å­˜: {report_filename}")
print(f"ğŸ“ˆ æˆåŠŸç‡: {len(successful_reports)}/{len(companies)} ({len(successful_reports)/len(companies)*100:.1f}%)")
