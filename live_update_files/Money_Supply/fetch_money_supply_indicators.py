#!/usr/bin/env python3
"""
æŠ“å–Money SupplyæŒ‡æ ‡æ•°æ®åˆ°Djangoæ•°æ®åº“
åŸºäºå®é™…ä½¿ç”¨çš„fetch_debt_indicators.py
"""

import os
import sys
import django
from datetime import datetime
import logging
import time

# æ·»åŠ Djangoé¡¹ç›®è·¯å¾„
sys.path.append('/Volumes/Pickle Samsung SSD/MEM Dashboard 2/src/django_api')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'django_api.settings')

# åˆå§‹åŒ–Django
django.setup()

from fred_us.data_fetcher import UsFredDataFetcher
from fred_us.models import FredUsIndicator
from django.db import transaction
from django.db.utils import IntegrityError

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'/Volumes/Pickle Samsung SSD/MEM Dashboard 2/logs/fetch_money_supply_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MoneySupplyDataFetcher:
    """Money Supplyæ•°æ®æŠ“å–å™¨ç±»"""
    
    def __init__(self):
        self.fetcher = UsFredDataFetcher()
        self.indicators = {
            'FEDFUNDS': {
                'name': 'Federal Funds Rate',
                'type': 'Money Supply',
                'description': 'è”é‚¦åŸºé‡‘åˆ©ç‡ - ç¾è”å‚¨åŸºå‡†åˆ©ç‡',
                'unit': 'Percent',
                'validation': {
                    'min_value': 0,
                    'max_value': 20,
                    'required_fields': ['date', 'value']
                }
            },
            'M2SL': {
                'name': 'M2 Money Supply',
                'type': 'Money Supply',
                'description': 'M2è´§å¸ä¾›åº”é‡ - å¹¿ä¹‰è´§å¸ä¾›åº”é‡',
                'unit': 'Billions of Dollars',
                'validation': {
                    'min_value': 0,
                    'max_value': None,
                    'required_fields': ['date', 'value']
                }
            },
            'WALCL': {
                'name': 'Federal Reserve Balance Sheet Total Assets',
                'type': 'Money Supply',
                'description': 'ç¾è”å‚¨èµ„äº§è´Ÿå€ºè¡¨æ€»èµ„äº§',
                'unit': 'Millions of U.S. Dollars',
                'validation': {
                    'min_value': 0,
                    'max_value': None,
                    'required_fields': ['date', 'value']
                }
            },
            'DRTSCIS': {
                'name': 'Bank Lending Standards',
                'type': 'Money Supply',
                'description': 'é“¶è¡Œè´·æ¬¾æ ‡å‡† - å¯¹å°ä¼ä¸šå•†ä¸šè´·æ¬¾æ ‡å‡†æ”¶ç´§çš„é“¶è¡Œå‡€ç™¾åˆ†æ¯”',
                'unit': 'Percent',
                'validation': {
                    'min_value': -100,
                    'max_value': 100,
                    'required_fields': ['date', 'value']
                }
            },
            'TOTLL': {
                'name': 'Commercial Banks Total Loans and Leases',
                'type': 'Money Supply',
                'description': 'å•†ä¸šé“¶è¡Œè´·æ¬¾å’Œç§Ÿèµæ€»é¢',
                'unit': 'Billions of U.S. Dollars',
                'validation': {
                    'min_value': 0,
                    'max_value': None,
                    'required_fields': ['date', 'value']
                }
            },
            'IORB': {
                'name': 'Interest Rate on Reserve Balances',
                'type': 'Money Supply',
                'description': 'å‡†å¤‡é‡‘ä½™é¢åˆ©ç‡ - IORBåˆ©ç‡',
                'unit': 'Percent',
                'validation': {
                    'min_value': 0,
                    'max_value': 20,
                    'required_fields': ['date', 'value']
                }
            },
            'RRPONTSYD': {
                'name': 'Overnight Reverse Repurchase Agreements',
                'type': 'Money Supply',
                'description': 'éš”å¤œé€†å›è´­åè®® - ç¾è”å‚¨ä¸´æ—¶å…¬å¼€å¸‚åœºæ“ä½œå‡ºå”®çš„å›½å€º',
                'unit': 'Billions of US Dollars',
                'validation': {
                    'min_value': 0,
                    'max_value': None,
                    'required_fields': ['date', 'value']
                }
            },
            'M1SL': {
                'name': 'M1 Money Supply',
                'type': 'Money Supply',
                'description': 'M1è´§å¸ä¾›åº”é‡ - ç‹­ä¹‰è´§å¸ä¾›åº”é‡',
                'unit': 'Billions of Dollars',
                'validation': {
                    'min_value': 0,
                    'max_value': None,
                    'required_fields': ['date', 'value']
                }
            }
        }
        
        self.stats = {
            'total_fetched': 0,
            'total_saved': 0,
            'total_errors': 0,
            'series_processed': 0,
            'start_time': datetime.now()
        }
    
    def validate_observation(self, obs, series_id):
        """éªŒè¯å•ä¸ªè§‚æµ‹æ•°æ®"""
        try:
            # åŸºæœ¬å­—æ®µæ£€æŸ¥
            required_fields = self.indicators[series_id]['validation']['required_fields']
            for field in required_fields:
                if field not in obs or obs[field] is None:
                    return False, f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}"
            
            # å€¼éªŒè¯
            if obs['value'] == '.' or obs['value'] == '' or obs['value'] is None:
                return False, "ç©ºå€¼"
            
            try:
                value = float(obs['value'])
            except (ValueError, TypeError):
                return False, f"æ— æ•ˆæ•°å€¼: {obs['value']}"
            
            # èŒƒå›´éªŒè¯
            validation = self.indicators[series_id]['validation']
            if validation['min_value'] is not None and value < validation['min_value']:
                return False, f"å€¼ä½äºæœ€å°å€¼: {value} < {validation['min_value']}"
            
            if validation['max_value'] is not None and value > validation['max_value']:
                return False, f"å€¼è¶…è¿‡æœ€å¤§å€¼: {value} > {validation['max_value']}"
            
            # æ—¥æœŸéªŒè¯
            try:
                date = datetime.strptime(obs['date'], '%Y-%m-%d').date()
                if date > datetime.now().date():
                    return False, f"æœªæ¥æ—¥æœŸ: {obs['date']}"
            except ValueError:
                return False, f"æ— æ•ˆæ—¥æœŸæ ¼å¼: {obs['date']}"
            
            return True, "éªŒè¯é€šè¿‡"
            
        except Exception as e:
            return False, f"éªŒè¯å¼‚å¸¸: {str(e)}"
    
    def save_observations_batch(self, observations, series_id):
        """æ‰¹é‡ä¿å­˜è§‚æµ‹æ•°æ®ï¼ŒåŒ…å«äº‹åŠ¡å¤„ç†"""
        saved_count = 0
        error_count = 0
        batch_size = 100  # æ‰¹å¤„ç†å¤§å°
        
        indicator_info = self.indicators[series_id]
        
        # åˆ†æ‰¹å¤„ç†æ•°æ®
        for i in range(0, len(observations), batch_size):
            batch = observations[i:i + batch_size]
            
            try:
                with transaction.atomic():
                    for obs in batch:
                        # æ•°æ®éªŒè¯
                        is_valid, message = self.validate_observation(obs, series_id)
                        if not is_valid:
                            logger.warning(f"{series_id} - è·³è¿‡æ— æ•ˆæ•°æ®: {message}")
                            continue
                        
                        try:
                            value = float(obs['value'])
                            date = datetime.strptime(obs['date'], '%Y-%m-%d').date()
                            
                            # ä½¿ç”¨get_or_createé¿å…é‡å¤
                            indicator, created = FredUsIndicator.objects.get_or_create(
                                series_id=series_id,
                                date=date,
                                defaults={
                                    'indicator_name': indicator_info['name'],
                                    'indicator_type': indicator_info['type'],
                                    'value': value,
                                    'source': 'FRED',
                                    'unit': indicator_info.get('unit', ''),
                                    'frequency': '',
                                    'metadata': {
                                        'description': indicator_info['description'],
                                        'original_value': obs['value']
                                    }
                                }
                            )
                            
                            if created:
                                saved_count += 1
                                
                        except IntegrityError as e:
                            logger.warning(f"{series_id} - æ•°æ®é‡å¤æˆ–çº¦æŸå†²çª: {str(e)}")
                            continue
                        except Exception as e:
                            logger.error(f"{series_id} - ä¿å­˜å¤±è´¥: {str(e)}")
                            error_count += 1
                            continue
                
                logger.info(f"{series_id} - æ‰¹æ¬¡ {i//batch_size + 1} å¤„ç†å®Œæˆ")
                
            except Exception as e:
                logger.error(f"{series_id} - æ‰¹æ¬¡å¤„ç†å¤±è´¥: {str(e)}")
                error_count += len(batch)
                continue
        
        return saved_count, error_count
    
    def fetch_series_with_retry(self, series_id, max_retries=3, delay=1):
        """å¸¦é‡è¯•æœºåˆ¶çš„æ•°æ®è·å–"""
        for attempt in range(max_retries):
            try:
                logger.info(f"å°è¯•è·å– {series_id} (ç¬¬ {attempt + 1} æ¬¡)")
                observations = self.fetcher.get_series_observations(series_id, limit=1000)
                
                if observations:
                    logger.info(f"âœ… æˆåŠŸè·å– {series_id}: {len(observations)} æ¡æ•°æ®")
                    return observations
                else:
                    logger.warning(f"âš ï¸ {series_id}: APIè¿”å›ç©ºæ•°æ®")
                    
            except Exception as e:
                logger.error(f"âŒ {series_id} è·å–å¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < max_retries - 1:
                    logger.info(f"ç­‰å¾… {delay} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    delay *= 2  # æŒ‡æ•°é€€é¿
        
        return None
    
    def fetch_indicator(self, series_id):
        """è·å–å•ä¸ªæŒ‡æ ‡æ•°æ®"""
        logger.info(f"\n{'='*20} å¤„ç†æŒ‡æ ‡: {series_id} {'='*20}")
        
        # æ£€æŸ¥ç°æœ‰æ•°æ®
        existing_count = FredUsIndicator.objects.filter(series_id=series_id).count()
        logger.info(f"æ•°æ®åº“ä¸­ç°æœ‰è®°å½•æ•°: {existing_count}")
        
        # è·å–æ•°æ®
        observations = self.fetch_series_with_retry(series_id)
        if not observations:
            logger.error(f"âŒ {series_id}: æ— æ³•è·å–æ•°æ®")
            self.stats['total_errors'] += 1
            return False
        
        self.stats['total_fetched'] += len(observations)
        
        # ä¿å­˜æ•°æ®
        logger.info(f"å¼€å§‹ä¿å­˜ {len(observations)} æ¡è§‚æµ‹æ•°æ®...")
        saved_count, error_count = self.save_observations_batch(observations, series_id)
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats['total_saved'] += saved_count
        self.stats['total_errors'] += error_count
        self.stats['series_processed'] += 1
        
        # éªŒè¯ä¿å­˜ç»“æœ
        final_count = FredUsIndicator.objects.filter(series_id=series_id).count()
        
        logger.info(f"âœ… {series_id} å¤„ç†å®Œæˆ:")
        logger.info(f"   - ä»APIè·å–: {len(observations)} æ¡")
        logger.info(f"   - æ–°ä¿å­˜: {saved_count} æ¡")
        logger.info(f"   - é”™è¯¯: {error_count} æ¡")
        logger.info(f"   - æ•°æ®åº“æ€»è®¡: {final_count} æ¡")
        
        if final_count > 0:
            latest = FredUsIndicator.objects.filter(series_id=series_id).order_by('-date').first()
            logger.info(f"   - æœ€æ–°æ•°æ®: {latest.value} ({latest.date})")
        
        return True
    
    def generate_summary_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„æ‰§è¡Œæ€»ç»“æŠ¥å‘Š"""
        duration = datetime.now() - self.stats['start_time']
        
        logger.info("\n" + "="*80)
        logger.info("ğŸ“Š Money Supplyæ•°æ®æŠ“å–æ€»ç»“æŠ¥å‘Š")
        logger.info("="*80)
        
        logger.info(f"æ‰§è¡Œæ—¶é—´: {duration}")
        logger.info(f"å¤„ç†åºåˆ—: {self.stats['series_processed']} / {len(self.indicators)}")
        logger.info(f"æ€»è·å–é‡: {self.stats['total_fetched']} æ¡")
        logger.info(f"æ€»ä¿å­˜é‡: {self.stats['total_saved']} æ¡")
        logger.info(f"æ€»é”™è¯¯æ•°: {self.stats['total_errors']} æ¡")
        
        if self.stats['total_fetched'] > 0:
            success_rate = (self.stats['total_saved'] / self.stats['total_fetched']) * 100
            logger.info(f"æˆåŠŸç‡: {success_rate:.1f}%")
        
        logger.info("\nå„åºåˆ—è¯¦ç»†çŠ¶æ€:")
        for series_id, info in self.indicators.items():
            count = FredUsIndicator.objects.filter(series_id=series_id).count()
            if count > 0:
                latest = FredUsIndicator.objects.filter(series_id=series_id).order_by('-date').first()
                logger.info(f"âœ… {series_id}: {count} æ¡è®°å½• (æœ€æ–°: {latest.date})")
            else:
                logger.info(f"âŒ {series_id}: æ— æ•°æ®")
    
    def run(self):
        """ä¸»æ‰§è¡Œæµç¨‹"""
        logger.info(f"ğŸš€ å¼€å§‹æŠ“å–Money SupplyæŒ‡æ ‡æ•°æ®...")
        logger.info(f"ğŸ“Š æ€»å…±éœ€è¦å¤„ç† {len(self.indicators)} ä¸ªæŒ‡æ ‡")
        
        success_count = 0
        
        for series_id in self.indicators.keys():
            try:
                if self.fetch_indicator(series_id):
                    success_count += 1
                
                # è¯·æ±‚é—´éš”ï¼Œé¿å…APIé™åˆ¶
                time.sleep(0.5)
                
            except KeyboardInterrupt:
                logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
                break
            except Exception as e:
                logger.error(f"âŒ {series_id} å¤„ç†å¼‚å¸¸: {str(e)}")
                continue
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.generate_summary_report()
        
        # æ‰§è¡Œç»“æœ
        if success_count == len(self.indicators):
            logger.info("ğŸ‰ æ‰€æœ‰Money SupplyæŒ‡æ ‡æ•°æ®æŠ“å–å®Œæˆ")
            return True
        else:
            logger.warning(f"âš ï¸ éƒ¨åˆ†æŒ‡æ ‡å¤„ç†å¤±è´¥: {success_count}/{len(self.indicators)}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    try:
        fetcher = MoneySupplyDataFetcher()
        success = fetcher.run()
        
        if success:
            logger.info("âœ… Money Supplyæ•°æ®æŠ“å–ä»»åŠ¡æˆåŠŸå®Œæˆ")
            sys.exit(0)
        else:
            logger.error("âŒ Money Supplyæ•°æ®æŠ“å–ä»»åŠ¡éƒ¨åˆ†å¤±è´¥")
            sys.exit(1)
            
    except Exception as e:
        logger.error(f"ğŸ’¥ ç³»ç»Ÿå¼‚å¸¸: {str(e)}")
        sys.exit(2)

if __name__ == "__main__":
    main()
