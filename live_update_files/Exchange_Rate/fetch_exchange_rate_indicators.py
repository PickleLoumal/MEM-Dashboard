#!/usr/bin/env python3
"""
æŠ“å–Exchange Rateæ±‡ç‡å’Œç›¸å…³é‡‘èæŒ‡æ ‡æ•°æ®åˆ°Djangoæ•°æ®åº“
åŸºäºtrade_deficitsæ¨¡æ¿ï¼Œä¸“æ³¨äºæ±‡ç‡ã€åˆ©ç‡ã€è´¸æ˜“å¹³è¡¡ç­‰é‡‘èå¸‚åœºæŒ‡æ ‡
"""

import os
import sys
import django
from datetime import datetime
import logging
import time

# æ·»åŠ Djangoé¡¹ç›®è·¯å¾„
sys.path.append('/Volumes/Pickle Samsung SSD/MEM Dashboard 2/src/django_api')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'django_api.settings')

# åˆå§‹åŒ–Django
django.setup()

from fred_us.data_fetcher import UsFredDataFetcher
from fred_us.models import FredUsIndicator
from django.db import transaction
from django.db.utils import IntegrityError

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'/Volumes/Pickle Samsung SSD/MEM Dashboard 2/logs/fetch_exchange_rate_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ExchangeRateDataFetcher:
    """Exchange Rateæ•°æ®æŠ“å–å™¨ç±»"""
    
    def __init__(self):
        self.fetcher = UsFredDataFetcher()
        self.indicators = {
            # Real Effective Exchange Rate (REER)
            'RBUSBIS': {
                'name': 'Real Effective Exchange Rate (REER)',
                'type': 'Exchange Rate',
                'description': 'å®é™…æœ‰æ•ˆæ±‡ç‡ - è¡¡é‡ç¾å…ƒç›¸å¯¹äºä¸€ç¯®å­è´§å¸çš„å®é™…è´­ä¹°åŠ›',
                'unit': 'Index',
                'validation': {
                    'min_value': 50,
                    'max_value': 200,
                    'required_fields': ['date', 'value']
                }
            },
            # Federal Funds Rate (Effective)
            'FEDFUNDS': {
                'name': 'Federal Funds Rate (Effective)',
                'type': 'Exchange Rate',
                'description': 'è”é‚¦åŸºé‡‘åˆ©ç‡ï¼ˆæœ‰æ•ˆåˆ©ç‡ï¼‰ - ç¾è”å‚¨åŸºå‡†åˆ©ç‡',
                'unit': 'Percent',
                'validation': {
                    'min_value': 0,
                    'max_value': 20,
                    'required_fields': ['date', 'value']
                }
            },
            # U.S. Trade Balance
            'BOPGSTB': {
                'name': 'U.S. Trade Balance',
                'type': 'Exchange Rate',
                'description': 'ç¾å›½è´¸æ˜“å¹³è¡¡ - å•†å“å’ŒæœåŠ¡è´¸æ˜“å·®é¢',
                'unit': 'Millions of Dollars',
                'validation': {
                    'min_value': None,
                    'max_value': None,
                    'required_fields': ['date', 'value']
                }
            },
            # China/US Exchange Rate
            'DEXCHUS': {
                'name': 'China/US Exchange Rate',
                'type': 'Exchange Rate',
                'description': 'äººæ°‘å¸/ç¾å…ƒæ±‡ç‡ - 1ç¾å…ƒå…‘æ¢äººæ°‘å¸',
                'unit': 'Chinese Yuan Renminbi to One U.S. Dollar',
                'validation': {
                    'min_value': 1.0,
                    'max_value': 10.0,
                    'required_fields': ['date', 'value']
                }
            },
            # 10-Year Treasury Yield
            'GS10': {
                'name': '10-Year Treasury Yield',
                'type': 'Exchange Rate',
                'description': '10å¹´æœŸç¾å›½å›½å€ºæ”¶ç›Šç‡ - é•¿æœŸåˆ©ç‡åŸºå‡†',
                'unit': 'Percent',
                'validation': {
                    'min_value': 0,
                    'max_value': 20,
                    'required_fields': ['date', 'value']
                }
            },
            # USD/EUR Exchange Rate
            'DEXUSEU': {
                'name': 'USD/EUR Exchange Rate',
                'type': 'Exchange Rate',
                'description': 'ç¾å…ƒ/æ¬§å…ƒæ±‡ç‡ - 1ç¾å…ƒå…‘æ¢æ¬§å…ƒ',
                'unit': 'Euro per Dollar',
                'validation': {
                    'min_value': 0.5,
                    'max_value': 2.0,
                    'required_fields': ['date', 'value']
                }
            },
            # Trade-Weighted U.S. Dollar Index (Broad)
            'DTWEXBGS': {
                'name': 'Trade-Weighted U.S. Dollar Index (Broad)',
                'type': 'Exchange Rate',
                'description': 'è´¸æ˜“åŠ æƒç¾å…ƒæŒ‡æ•°ï¼ˆå¹¿ä¹‰ï¼‰ - ç¾å…ƒç›¸å¯¹äºä¸»è¦è´¸æ˜“ä¼™ä¼´è´§å¸çš„å¼ºåº¦',
                'unit': 'Index Jan 2006=100',
                'validation': {
                    'min_value': 80,
                    'max_value': 140,
                    'required_fields': ['date', 'value']
                }
            },
            # JPMorgan Global FX Volatility Index (VXY) - ä½¿ç”¨VIXä½œä¸ºæ›¿ä»£
            'VIXCLS': {
                'name': 'CBOE Volatility Index (VIX)',
                'type': 'Exchange Rate',
                'description': 'CBOEæ³¢åŠ¨ç‡æŒ‡æ•° - å¸‚åœºææ…ŒæŒ‡æ•°ï¼Œåæ˜ é‡‘èå¸‚åœºæ³¢åŠ¨æ€§',
                'unit': 'Index',
                'validation': {
                    'min_value': 5,
                    'max_value': 100,
                    'required_fields': ['date', 'value']
                }
            },
            # Japan/US Exchange Rate
            'DEXJPUS': {
                'name': 'Japan/US Exchange Rate',
                'type': 'Exchange Rate',
                'description': 'æ—¥å…ƒ/ç¾å…ƒæ±‡ç‡ - 1ç¾å…ƒå…‘æ¢æ—¥å…ƒ',
                'unit': 'Japanese Yen to One U.S. Dollar',
                'validation': {
                    'min_value': 80,
                    'max_value': 200,
                    'required_fields': ['date', 'value']
                }
            }
        }
        
        self.stats = {
            'total_fetched': 0,
            'total_saved': 0,
            'total_errors': 0,
            'series_processed': 0,
            'start_time': datetime.now()
        }
    
    def validate_observation(self, obs, series_id):
        """éªŒè¯å•ä¸ªè§‚æµ‹æ•°æ®"""
        try:
            # åŸºæœ¬å­—æ®µæ£€æŸ¥
            required_fields = self.indicators[series_id]['validation']['required_fields']
            for field in required_fields:
                if field not in obs or obs[field] is None:
                    return False, f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}"
            
            # å€¼éªŒè¯
            if obs['value'] == '.' or obs['value'] == '' or obs['value'] is None:
                return False, "ç©ºå€¼"
            
            try:
                value = float(obs['value'])
            except (ValueError, TypeError):
                return False, f"æ— æ•ˆæ•°å€¼: {obs['value']}"
            
            # èŒƒå›´éªŒè¯
            validation = self.indicators[series_id]['validation']
            if validation['min_value'] is not None and value < validation['min_value']:
                return False, f"å€¼ä½äºæœ€å°å€¼: {value} < {validation['min_value']}"
            
            if validation['max_value'] is not None and value > validation['max_value']:
                return False, f"å€¼è¶…è¿‡æœ€å¤§å€¼: {value} > {validation['max_value']}"
            
            # æ—¥æœŸéªŒè¯
            try:
                date = datetime.strptime(obs['date'], '%Y-%m-%d').date()
                if date > datetime.now().date():
                    return False, f"æœªæ¥æ—¥æœŸ: {obs['date']}"
            except ValueError:
                return False, f"æ— æ•ˆæ—¥æœŸæ ¼å¼: {obs['date']}"
            
            return True, "éªŒè¯é€šè¿‡"
            
        except Exception as e:
            return False, f"éªŒè¯å¼‚å¸¸: {str(e)}"
    
    def save_observations_batch(self, observations, series_id):
        """æ‰¹é‡ä¿å­˜è§‚æµ‹æ•°æ®ï¼ŒåŒ…å«äº‹åŠ¡å¤„ç†"""
        saved_count = 0
        error_count = 0
        batch_size = 100  # æ‰¹å¤„ç†å¤§å°
        
        indicator_info = self.indicators[series_id]
        
        # åˆ†æ‰¹å¤„ç†æ•°æ®
        for i in range(0, len(observations), batch_size):
            batch = observations[i:i + batch_size]
            
            try:
                with transaction.atomic():
                    for obs in batch:
                        # æ•°æ®éªŒè¯
                        is_valid, message = self.validate_observation(obs, series_id)
                        if not is_valid:
                            logger.warning(f"{series_id} - è·³è¿‡æ— æ•ˆæ•°æ®: {message}")
                            continue
                        
                        try:
                            value = float(obs['value'])
                            date = datetime.strptime(obs['date'], '%Y-%m-%d').date()
                            
                            # ä½¿ç”¨get_or_createé¿å…é‡å¤
                            indicator, created = FredUsIndicator.objects.get_or_create(
                                series_id=series_id,
                                date=date,
                                defaults={
                                    'indicator_name': indicator_info['name'],
                                    'indicator_type': indicator_info['type'],
                                    'value': value,
                                    'source': 'FRED',
                                    'unit': indicator_info.get('unit', ''),
                                    'frequency': '',
                                    'metadata': {
                                        'description': indicator_info['description'],
                                        'original_value': obs['value']
                                    }
                                }
                            )
                            
                            if created:
                                saved_count += 1
                                
                        except IntegrityError as e:
                            logger.warning(f"{series_id} - æ•°æ®é‡å¤æˆ–çº¦æŸå†²çª: {str(e)}")
                            continue
                        except Exception as e:
                            logger.error(f"{series_id} - ä¿å­˜å¤±è´¥: {str(e)}")
                            error_count += 1
                            continue
                
                logger.info(f"{series_id} - æ‰¹æ¬¡ {i//batch_size + 1} å¤„ç†å®Œæˆ")
                
            except Exception as e:
                logger.error(f"{series_id} - æ‰¹æ¬¡å¤„ç†å¤±è´¥: {str(e)}")
                error_count += len(batch)
                continue
        
        return saved_count, error_count
    
    def fetch_series_with_retry(self, series_id, max_retries=3, delay=1):
        """å¸¦é‡è¯•æœºåˆ¶çš„æ•°æ®è·å–"""
        for attempt in range(max_retries):
            try:
                logger.info(f"å°è¯•è·å– {series_id} (ç¬¬ {attempt + 1} æ¬¡)")
                observations = self.fetcher.get_series_observations(series_id, limit=1000)
                
                if observations:
                    logger.info(f"âœ… æˆåŠŸè·å– {series_id}: {len(observations)} æ¡æ•°æ®")
                    return observations
                else:
                    logger.warning(f"âš ï¸ {series_id}: APIè¿”å›ç©ºæ•°æ®")
                    
            except Exception as e:
                logger.error(f"âŒ {series_id} è·å–å¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < max_retries - 1:
                    logger.info(f"ç­‰å¾… {delay} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    delay *= 2  # æŒ‡æ•°é€€é¿
        
        return None
    
    def fetch_indicator(self, series_id):
        """è·å–å•ä¸ªæŒ‡æ ‡æ•°æ®"""
        logger.info(f"\n{'='*20} å¤„ç†æŒ‡æ ‡: {series_id} {'='*20}")
        
        # æ£€æŸ¥ç°æœ‰æ•°æ®
        existing_count = FredUsIndicator.objects.filter(series_id=series_id).count()
        logger.info(f"æ•°æ®åº“ä¸­ç°æœ‰è®°å½•æ•°: {existing_count}")
        
        # è·å–æ•°æ®
        observations = self.fetch_series_with_retry(series_id)
        if not observations:
            logger.error(f"âŒ {series_id}: æ— æ³•è·å–æ•°æ®")
            self.stats['total_errors'] += 1
            return False
        
        self.stats['total_fetched'] += len(observations)
        
        # ä¿å­˜æ•°æ®
        logger.info(f"å¼€å§‹ä¿å­˜ {len(observations)} æ¡è§‚æµ‹æ•°æ®...")
        saved_count, error_count = self.save_observations_batch(observations, series_id)
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats['total_saved'] += saved_count
        self.stats['total_errors'] += error_count
        self.stats['series_processed'] += 1
        
        # éªŒè¯ä¿å­˜ç»“æœ
        final_count = FredUsIndicator.objects.filter(series_id=series_id).count()
        
        logger.info(f"âœ… {series_id} å¤„ç†å®Œæˆ:")
        logger.info(f"   - ä»APIè·å–: {len(observations)} æ¡")
        logger.info(f"   - æ–°ä¿å­˜: {saved_count} æ¡")
        logger.info(f"   - é”™è¯¯: {error_count} æ¡")
        logger.info(f"   - æ•°æ®åº“æ€»è®¡: {final_count} æ¡")
        
        if final_count > 0:
            latest = FredUsIndicator.objects.filter(series_id=series_id).order_by('-date').first()
            logger.info(f"   - æœ€æ–°æ•°æ®: {latest.value} ({latest.date})")
        
        return True
    
    def generate_summary_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„æ‰§è¡Œæ€»ç»“æŠ¥å‘Š"""
        duration = datetime.now() - self.stats['start_time']
        
        logger.info("\n" + "="*80)
        logger.info("ğŸ“Š Exchange Rateæ±‡ç‡æŒ‡æ ‡æ•°æ®æŠ“å–æ€»ç»“æŠ¥å‘Š")
        logger.info("="*80)
        
        logger.info(f"æ‰§è¡Œæ—¶é—´: {duration}")
        logger.info(f"å¤„ç†åºåˆ—: {self.stats['series_processed']} / {len(self.indicators)}")
        logger.info(f"æ€»è·å–é‡: {self.stats['total_fetched']} æ¡")
        logger.info(f"æ€»ä¿å­˜é‡: {self.stats['total_saved']} æ¡")
        logger.info(f"æ€»é”™è¯¯æ•°: {self.stats['total_errors']} æ¡")
        
        if self.stats['total_fetched'] > 0:
            success_rate = (self.stats['total_saved'] / self.stats['total_fetched']) * 100
            logger.info(f"æˆåŠŸç‡: {success_rate:.1f}%")
        
        logger.info("\nå„åºåˆ—è¯¦ç»†çŠ¶æ€:")
        for series_id, info in self.indicators.items():
            count = FredUsIndicator.objects.filter(series_id=series_id).count()
            if count > 0:
                latest = FredUsIndicator.objects.filter(series_id=series_id).order_by('-date').first()
                logger.info(f"âœ… {series_id}: {count} æ¡è®°å½• (æœ€æ–°: {latest.date})")
            else:
                logger.info(f"âŒ {series_id}: æ— æ•°æ®")
    
    def run(self):
        """ä¸»æ‰§è¡Œæµç¨‹"""
        logger.info(f"ğŸš€ å¼€å§‹æŠ“å–Exchange Rateæ±‡ç‡æŒ‡æ ‡æ•°æ®...")
        logger.info(f"ğŸ“Š æ€»å…±éœ€è¦å¤„ç† {len(self.indicators)} ä¸ªæŒ‡æ ‡")
        
        success_count = 0
        
        for series_id in self.indicators.keys():
            try:
                if self.fetch_indicator(series_id):
                    success_count += 1
                
                # è¯·æ±‚é—´éš”ï¼Œé¿å…APIé™åˆ¶
                time.sleep(0.5)
                
            except KeyboardInterrupt:
                logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
                break
            except Exception as e:
                logger.error(f"âŒ {series_id} å¤„ç†å¼‚å¸¸: {str(e)}")
                continue
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.generate_summary_report()
        
        # æ‰§è¡Œç»“æœ
        if success_count == len(self.indicators):
            logger.info("ğŸ‰ æ‰€æœ‰Exchange RateæŒ‡æ ‡æ•°æ®æŠ“å–å®Œæˆ")
            return True
        else:
            logger.warning(f"âš ï¸ éƒ¨åˆ†æŒ‡æ ‡å¤„ç†å¤±è´¥: {success_count}/{len(self.indicators)}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    try:
        fetcher = ExchangeRateDataFetcher()
        success = fetcher.run()
        
        if success:
            logger.info("âœ… Exchange Rateæ•°æ®æŠ“å–ä»»åŠ¡æˆåŠŸå®Œæˆ")
            sys.exit(0)
        else:
            logger.error("âŒ Exchange Rateæ•°æ®æŠ“å–ä»»åŠ¡éƒ¨åˆ†å¤±è´¥")
            sys.exit(1)
            
    except Exception as e:
        logger.error(f"ğŸ’¥ ç³»ç»Ÿå¼‚å¸¸: {str(e)}")
        sys.exit(2)

if __name__ == "__main__":
    main()
