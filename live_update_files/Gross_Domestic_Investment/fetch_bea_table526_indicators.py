#!/usr/bin/env python3
"""
BEA Table 5.2.6æŠ•èµ„æŒ‡æ ‡æ•°æ®æŠ“å–å™¨
ä»BEA APIè·å–Real Gross and Net Domestic Investment by Major Typeæ•°æ®å¹¶å­˜å‚¨åˆ°Djangoæ•°æ®åº“

åŸºäºæˆåŠŸæµ‹è¯•çš„BEA Table 5.2.6 (T50206) å¹´åº¦æ•°æ®
"""

import os
import sys
import django
from datetime import datetime, timedelta
import time
import logging
import urllib.request
import urllib.parse
import json

# æ·»åŠ Djangoé¡¹ç›®è·¯å¾„
sys.path.append('/Volumes/Pickle Samsung SSD/MEM Dashboard 2/src/django_api')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'django_api.settings')

# åˆå§‹åŒ–Django
django.setup()

from bea.models import BeaIndicator, BeaIndicatorConfig
from django.db import transaction
from django.db.utils import IntegrityError

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'/Volumes/Pickle Samsung SSD/MEM Dashboard 2/logs/fetch_bea_table526_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class BeaTable526DataFetcher:
    """BEA Table 5.2.6æŠ•èµ„æ•°æ®æŠ“å–å™¨ç±»"""
    
    def __init__(self):
        self.api_key = "DEFB02B6-33E9-4803-AEC1-73B03F4084B8"
        self.base_url = "https://apps.bea.gov/api/data"
        self.table_name = "T50206"  # ç»æµ‹è¯•æˆåŠŸçš„è¡¨å
        
        # åŸºäºCSVæ–‡ä»¶çœŸå®ç»“æ„çš„æŠ•èµ„æŒ‡æ ‡é…ç½®
        self.indicators = {
            'INVESTMENT_TOTAL': {
                'line_number': 4,
                'name': 'Gross Private Domestic Investment',
                'description': 'Gross private domestic investment',
                'category': 'investment',
                'units': 'Millions of Chained 2017 Dollars',
                'frequency': 'A'
            },
            'INVESTMENT_FIXED': {
                'line_number': 7,
                'name': 'Fixed Investment',
                'description': 'Fixed investment',
                'category': 'investment',
                'units': 'Millions of Chained 2017 Dollars',
                'frequency': 'A'
            },
            'INVESTMENT_NONRESIDENTIAL': {
                'line_number': 10,
                'name': 'Nonresidential Investment',
                'description': 'Nonresidential fixed investment',
                'category': 'investment',
                'units': 'Millions of Chained 2017 Dollars',
                'frequency': 'A'
            },
            'INVESTMENT_STRUCTURES': {
                'line_number': 13,
                'name': 'Structures',
                'description': 'Structures',
                'category': 'investment',
                'units': 'Millions of Chained 2017 Dollars',
                'frequency': 'A'
            },
            'INVESTMENT_EQUIPMENT': {
                'line_number': 16,
                'name': 'Equipment',
                'description': 'Equipment',
                'category': 'investment',
                'units': 'Millions of Chained 2017 Dollars',
                'frequency': 'A'
            },
            'INVESTMENT_IP': {
                'line_number': 19,
                'name': 'Intellectual Property Products',
                'description': 'Intellectual property products',
                'category': 'investment',
                'units': 'Millions of Chained 2017 Dollars',
                'frequency': 'A'
            },
            'INVESTMENT_RESIDENTIAL': {
                'line_number': 22,
                'name': 'Residential Investment',
                'description': 'Residential fixed investment',
                'category': 'investment',
                'units': 'Millions of Chained 2017 Dollars',
                'frequency': 'A'
            },
            'INVESTMENT_INVENTORIES': {
                'line_number': 25,
                'name': 'Change in Private Inventories',
                'description': 'Change in private inventories',
                'category': 'investment',
                'units': 'Millions of Chained 2017 Dollars',
                'frequency': 'A'
            },
            'INVESTMENT_NET': {
                'line_number': 6,
                'name': 'Net Private Domestic Investment',
                'description': 'Equals: Net private domestic investment',
                'category': 'investment',
                'units': 'Millions of Chained 2017 Dollars',
                'frequency': 'A'
            },
            'GOVT_INVESTMENT_TOTAL': {
                'line_number': 26,
                'name': 'Gross Government Investment',
                'description': 'Gross government investment',
                'category': 'government',
                'units': 'Millions of Chained 2017 Dollars',
                'frequency': 'A'
            }
        }
        
        self.stats = {
            'total_fetched': 0,
            'total_saved': 0,
            'total_errors': 0,
            'series_processed': 0,
            'start_time': datetime.now()
        }

    def fetch_bea_data(self, line_number, series_id, years='2000,2005,2010,2015,2020,2021,2022,2023,2024'):
        """ä»BEA APIè·å–Table 5.2.6æ•°æ®"""
        params = {
            'UserID': self.api_key,
            'method': 'GetData',
            'datasetname': 'NIPA',
            'TableName': self.table_name,
            'LineNumber': str(line_number),
            'Year': years,
            'Frequency': 'A',  # å¹´åº¦æ•°æ®
            'ResultFormat': 'JSON'
        }
        
        try:
            query_string = urllib.parse.urlencode(params)
            full_url = f"{self.base_url}?{query_string}"
            
            logger.info(f"æ­£åœ¨ä»BEA APIè·å– {series_id} æ•°æ®...")
            logger.debug(f"API URL: {full_url}")
            
            with urllib.request.urlopen(full_url) as response:
                bea_data = json.loads(response.read().decode())
            
            if 'BEAAPI' in bea_data:
                beaapi = bea_data['BEAAPI']
                
                # æ£€æŸ¥é”™è¯¯
                if 'Error' in beaapi:
                    logger.error(f"BEA APIé”™è¯¯: {beaapi['Error']}")
                    return None
                
                # è·å–æ•°æ®
                if 'Results' in beaapi and 'Data' in beaapi['Results']:
                    all_data_points = beaapi['Results']['Data']
                    logger.info(f"âœ… {series_id}: ä»APIè·å–åˆ° {len(all_data_points)} ä¸ªæ•°æ®ç‚¹ (æ•´ä¸ªè¡¨æ ¼)")
                    
                    # è¿‡æ»¤å‡ºæŒ‡å®šè¡Œå·çš„æ•°æ® - ä¿®å¤æ ¸å¿ƒé—®é¢˜
                    target_line_data = []
                    for data in all_data_points:
                        data_line_number = data.get('LineNumber', '')
                        if data_line_number == str(line_number):
                            target_line_data.append(data)
                    
                    if target_line_data:
                        logger.info(f"âœ… {series_id}: è¿‡æ»¤å‡ºè¡Œ {line_number} çš„æ•°æ®: {len(target_line_data)} ä¸ªæ•°æ®ç‚¹")
                        return target_line_data
                    else:
                        logger.warning(f"âš ï¸ {series_id}: æœªæ‰¾åˆ°è¡Œ {line_number} çš„æ•°æ®")
                        # æ˜¾ç¤ºå¯ç”¨çš„è¡Œå·ç”¨äºè°ƒè¯•
                        available_lines = set()
                        for data in all_data_points[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªä»¥é¿å…æ—¥å¿—è¿‡é•¿
                            available_lines.add(data.get('LineNumber', 'N/A'))
                        logger.debug(f"å¯ç”¨è¡Œå· (å‰10ä¸ª): {sorted(available_lines)}")
                        return None
                else:
                    logger.warning(f"âš ï¸ {series_id}: APIå“åº”æ ¼å¼é”™è¯¯")
                    return None
            else:
                logger.error(f"âŒ {series_id}: æ— æ•ˆçš„APIå“åº”")
                return None
                
        except Exception as e:
            logger.error(f"âŒ {series_id}: æ•°æ®è·å–å¤±è´¥ - {e}")
            return None

    def parse_time_period(self, time_period):
        """è§£æBEAæ—¶é—´æ ¼å¼ (ä¾‹å¦‚: 2023) è½¬æ¢ä¸ºæ—¥æœŸ"""
        try:
            year = int(time_period)
            # ä½¿ç”¨å¹´æœ«æ—¥æœŸ
            return datetime(year, 12, 31).date()
        except:
            logger.error(f"æ— æ³•è§£ææ—¶é—´æ ¼å¼: {time_period}")
            return None

    def save_indicator_data(self, series_id, data_points, indicator_info):
        """ä¿å­˜æŒ‡æ ‡æ•°æ®åˆ°æ•°æ®åº“ - ä¿å­˜æ‰€æœ‰æœ‰æ•ˆçš„æ•°æ®ç‚¹"""
        saved_count = 0
        error_count = 0

        try:
            with transaction.atomic():
                # å¤„ç†æ‰€æœ‰æœ‰æ•ˆçš„æ•°æ®ç‚¹ï¼ˆç°åœ¨data_pointså·²ç»æ˜¯è¿‡æ»¤åçš„æ­£ç¡®è¡Œå·æ•°æ®ï¼‰
                for data_point in data_points:
                    try:
                        # è§£ææ•°æ®
                        time_period = data_point.get('TimePeriod')
                        data_value = data_point.get('DataValue')

                        # è·³è¿‡æ— æ•ˆæ•°æ®
                        if not time_period or not data_value or data_value == '--':
                            continue

                        # è½¬æ¢æ•°å€¼ - ç§»é™¤é€—å·å¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                        try:
                            clean_value = str(data_value).replace(',', '')
                            value = float(clean_value)
                        except (ValueError, TypeError):
                            logger.warning(f"æ— æ³•è½¬æ¢æ•°å€¼ {series_id}: {data_value}")
                            error_count += 1
                            continue

                        # è§£ææ—¥æœŸ
                        date = self.parse_time_period(time_period)
                        if not date:
                            error_count += 1
                            continue

                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒseries_idå’Œæ—¥æœŸçš„è®°å½•ï¼Œå¦‚æœå­˜åœ¨åˆ™æ›´æ–°
                        existing_record = BeaIndicator.objects.filter(
                            series_id=series_id,
                            date=date
                        ).first()

                        if existing_record:
                            # æ›´æ–°ç°æœ‰è®°å½•
                            existing_record.value = value
                            existing_record.date = date
                            existing_record.time_period = time_period
                            existing_record.metadata.update({
                                'description': indicator_info['description'],
                                'table_5_2_6': True,
                                'api_fetched': datetime.now().isoformat(),
                                'raw_value': data_value,
                                'updated': True
                            })
                            existing_record.save()
                            logger.info(f"âœ… {series_id}: æ›´æ–°ç°æœ‰è®°å½• {time_period} - å€¼: {value}")
                        else:
                            # åˆ›å»ºæ–°è®°å½•
                            indicator = BeaIndicator(
                                series_id=series_id,
                                indicator_name=indicator_info['name'],
                                indicator_type=indicator_info['category'],
                                table_name=self.table_name,
                                line_number=str(indicator_info['line_number']),
                                date=date,
                                time_period=time_period,
                                value=value,
                                source='BEA',
                                unit=indicator_info['units'],
                                frequency=indicator_info['frequency'],
                                dataset_name='NIPA',
                                metadata={
                                    'description': indicator_info['description'],
                                    'table_5_2_6': True,
                                    'api_fetched': datetime.now().isoformat(),
                                    'raw_value': data_value
                                }
                            )
                            indicator.save()
                            logger.info(f"âœ… {series_id}: åˆ›å»ºæ–°è®°å½• {time_period} - å€¼: {value}")

                        saved_count += 1

                    except Exception as e:
                        logger.error(f"ä¿å­˜è®°å½•å¤±è´¥ {series_id} {time_period}: {e}")
                        error_count += 1

                logger.info(f"âœ… {series_id}: å¤„ç†å®Œæˆ - ä¿å­˜ {saved_count} æ¡ï¼Œå¤±è´¥ {error_count} æ¡")
                return saved_count, error_count
                
        except Exception as e:
            logger.error(f"âŒ {series_id}: æ•°æ®åº“äº‹åŠ¡å¤±è´¥ - {e}")
            return 0, len(data_points)

    def ensure_indicator_config(self, series_id, indicator_info):
        """ç¡®ä¿æŒ‡æ ‡é…ç½®å­˜åœ¨äºæ•°æ®åº“ä¸­"""
        try:
            config, created = BeaIndicatorConfig.objects.get_or_create(
                series_id=series_id,
                defaults={
                    'name': indicator_info['name'],
                    'description': indicator_info['description'],
                    'table_name': self.table_name,
                    'line_description': indicator_info['description'],
                    'line_number': indicator_info['line_number'],
                    'units': indicator_info['units'],
                    'frequency': indicator_info['frequency'],
                    'years': '2000,2005,2010,2015,2020,2021,2022,2023,2024',
                    'category': indicator_info['category'],
                    'api_endpoint': series_id.lower().replace('_', '-'),
                    'is_active': True,
                    'auto_fetch': True,
                    'dataset_name': 'NIPA',
                    'created_by': 'fetch_table526_script',
                    'updated_by': 'fetch_table526_script',
                    'additional_config': {
                        'table_5_2_6': True,
                        'chained_2017_dollars': True
                    }
                }
            )
            
            if created:
                logger.info(f"âœ… åˆ›å»ºæ–°é…ç½®: {series_id}")
            else:
                logger.debug(f"é…ç½®å·²å­˜åœ¨: {series_id}")
                
            return config
            
        except Exception as e:
            logger.error(f"âŒ é…ç½®åˆ›å»ºå¤±è´¥ {series_id}: {e}")
            return None

    def fetch_indicator(self, series_id):
        """è·å–å•ä¸ªæŒ‡æ ‡æ•°æ®"""
        logger.info(f"\n{'='*20} å¤„ç†æŒ‡æ ‡: {series_id} {'='*20}")
        
        indicator_info = self.indicators[series_id]
        
        # ç¡®ä¿é…ç½®å­˜åœ¨
        config = self.ensure_indicator_config(series_id, indicator_info)
        if not config:
            logger.error(f"âŒ {series_id}: æ— æ³•åˆ›å»ºæŒ‡æ ‡é…ç½®")
            return False
        
        # æ£€æŸ¥ç°æœ‰æ•°æ®
        existing_count = BeaIndicator.objects.filter(series_id=series_id).count()
        logger.info(f"æ•°æ®åº“ç°æœ‰è®°å½•: {existing_count}")
        
        # è·å–æ•°æ®
        data_points = self.fetch_bea_data(
            indicator_info['line_number'], 
            series_id
        )
        
        if not data_points:
            logger.error(f"âŒ {series_id}: æ— æ³•è·å–æ•°æ®")
            self.stats['total_errors'] += 1
            return False
        
        self.stats['total_fetched'] += len(data_points)
        
        # ä¿å­˜æ•°æ®
        saved_count, error_count = self.save_indicator_data(series_id, data_points, indicator_info)
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats['total_saved'] += saved_count
        self.stats['total_errors'] += error_count
        self.stats['series_processed'] += 1
        
        # éªŒè¯ä¿å­˜ç»“æœ
        final_count = BeaIndicator.objects.filter(series_id=series_id).count()
        if final_count > 0:
            latest = BeaIndicator.objects.filter(series_id=series_id).order_by('-date').first()
            logger.info(f"ğŸ“Š {series_id} æ€»è®°å½•æ•°: {final_count}")
            logger.info(f"ğŸ“Š æœ€æ–°æ•°æ®: {latest.value} ({latest.time_period})")
        
        return True

    def generate_summary_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„æ‰§è¡Œæ€»ç»“æŠ¥å‘Š"""
        duration = datetime.now() - self.stats['start_time']
        
        logger.info("\n" + "="*80)
        logger.info("ğŸ“Š BEA Table 5.2.6æŠ•èµ„æŒ‡æ ‡æ•°æ®æŠ“å–æ€»ç»“æŠ¥å‘Š")
        logger.info("="*80)
        
        logger.info(f"æ‰§è¡Œæ—¶é—´: {duration}")
        logger.info(f"è¡¨æ ¼: {self.table_name} (Real Gross and Net Domestic Investment)")
        logger.info(f"å¤„ç†åºåˆ—: {self.stats['series_processed']} / {len(self.indicators)}")
        logger.info(f"æ€»è·å–é‡: {self.stats['total_fetched']} æ¡")
        logger.info(f"æ€»ä¿å­˜é‡: {self.stats['total_saved']} æ¡")
        logger.info(f"æ€»é”™è¯¯æ•°: {self.stats['total_errors']} æ¡")
        
        if self.stats['total_fetched'] > 0:
            success_rate = (self.stats['total_saved'] / self.stats['total_fetched']) * 100
            logger.info(f"æˆåŠŸç‡: {success_rate:.1f}%")
        
        logger.info("\nå„åºåˆ—è¯¦ç»†çŠ¶æ€:")
        for series_id, info in self.indicators.items():
            count = BeaIndicator.objects.filter(series_id=series_id).count()
            if count > 0:
                latest = BeaIndicator.objects.filter(series_id=series_id).order_by('-date').first()
                logger.info(f"âœ… {series_id}: {count} æ¡è®°å½• (æœ€æ–°: {latest.time_period})")
            else:
                logger.info(f"âŒ {series_id}: æ— æ•°æ®")

    def run(self):
        """ä¸»æ‰§è¡Œæµç¨‹"""
        logger.info(f"ğŸš€ å¼€å§‹æŠ“å–BEA Table 5.2.6æŠ•èµ„æŒ‡æ ‡æ•°æ®...")
        logger.info(f"ğŸ“Š è¡¨æ ¼: {self.table_name}")
        logger.info(f"ğŸ“Š æ€»å…±éœ€è¦å¤„ç† {len(self.indicators)} ä¸ªæŒ‡æ ‡")
        
        success_count = 0
        
        for series_id in self.indicators.keys():
            try:
                if self.fetch_indicator(series_id):
                    success_count += 1
                
                # è¯·æ±‚é—´éš”ï¼Œé¿å…APIé™åˆ¶
                time.sleep(1)
                
            except KeyboardInterrupt:
                logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
                break
            except Exception as e:
                logger.error(f"âŒ {series_id} å¤„ç†å¼‚å¸¸: {e}")
                continue
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.generate_summary_report()
        
        # æ‰§è¡Œç»“æœ
        if success_count == len(self.indicators):
            logger.info("ğŸ‰ æ‰€æœ‰æŠ•èµ„æŒ‡æ ‡æ•°æ®æŠ“å–å®Œæˆ")
            return True
        else:
            logger.warning(f"âš ï¸ éƒ¨åˆ†æŒ‡æ ‡å¤„ç†å¤±è´¥: {success_count}/{len(self.indicators)}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("=" * 60)
        logger.info("BEA Table 5.2.6æŠ•èµ„æŒ‡æ ‡æ•°æ®æŠ“å–å™¨å¯åŠ¨")
        logger.info("=" * 60)
        
        fetcher = BeaTable526DataFetcher()
        success = fetcher.run()
        
        if success:
            logger.info("âœ… æ•°æ®æŠ“å–ä»»åŠ¡æˆåŠŸå®Œæˆ")
            sys.exit(0)
        else:
            logger.error("âŒ æ•°æ®æŠ“å–ä»»åŠ¡éƒ¨åˆ†å¤±è´¥")
            sys.exit(1)
            
    except Exception as e:
        logger.error(f"ğŸ’¥ ç³»ç»Ÿå¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(2)

if __name__ == "__main__":
    main()

